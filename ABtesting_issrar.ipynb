{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning and analysis for A/B testing\n",
    "\n",
    "Hypotheses\n",
    "H0: null hypothesis (change in revenue observed in treatment group is *not* statistically significant)\n",
    "H1: reject null hypothesis (change is statistically significant and new membership model is going to make us lots of money)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "control group: old design\n",
    "treatment group: new design\n",
    "\n",
    "dependent variable: change in revenue\n",
    "\n",
    "\n",
    "# choose sample size?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import statsmodels.stats.api as sm\n",
    "from scipy.stats import shapiro, mannwhitneyu, anderson, kstest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.11), please consider upgrading to the latest version (0.3.12).\n",
      "Path to dataset files: /Users/issrar/.cache/kagglehub/datasets/sergylog/ab-test-data/versions/3\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"sergylog/ab-test-data\")\n",
    "\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "USER_ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "VARIANT_NAME",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "REVENUE",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "453bbbaf-8eff-4e5f-aa34-72b2433f208d",
       "rows": [
        [
         "0",
         "737",
         "variant",
         "0.0"
        ],
        [
         "1",
         "2423",
         "control",
         "0.0"
        ],
        [
         "2",
         "9411",
         "control",
         "0.0"
        ],
        [
         "3",
         "7311",
         "control",
         "0.0"
        ],
        [
         "4",
         "6174",
         "variant",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>VARIANT_NAME</th>\n",
       "      <th>REVENUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>737</td>\n",
       "      <td>variant</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2423</td>\n",
       "      <td>control</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9411</td>\n",
       "      <td>control</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7311</td>\n",
       "      <td>control</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6174</td>\n",
       "      <td>variant</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   USER_ID VARIANT_NAME  REVENUE\n",
       "0      737      variant      0.0\n",
       "1     2423      control      0.0\n",
       "2     9411      control      0.0\n",
       "3     7311      control      0.0\n",
       "4     6174      variant      0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path + \"/AB_Test_Results.csv\").copy()\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (10000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c3aaf_row0_col1, #T_c3aaf_row0_col2, #T_c3aaf_row1_col1, #T_c3aaf_row1_col2, #T_c3aaf_row1_col3, #T_c3aaf_row2_col1, #T_c3aaf_row2_col2 {\n",
       "  background-color: #f7fcf0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c3aaf_row0_col3, #T_c3aaf_row3_col1, #T_c3aaf_row3_col2 {\n",
       "  background-color: #084081;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c3aaf_row2_col3 {\n",
       "  background-color: #f4fbed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c3aaf_row3_col3 {\n",
       "  background-color: #b6e3bb;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c3aaf\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c3aaf_level0_col0\" class=\"col_heading level0 col0\" >data type</th>\n",
       "      <th id=\"T_c3aaf_level0_col1\" class=\"col_heading level0 col1\" >number of missing values</th>\n",
       "      <th id=\"T_c3aaf_level0_col2\" class=\"col_heading level0 col2\" >percent missing</th>\n",
       "      <th id=\"T_c3aaf_level0_col3\" class=\"col_heading level0 col3\" >number of unique values</th>\n",
       "      <th id=\"T_c3aaf_level0_col4\" class=\"col_heading level0 col4\" >mean</th>\n",
       "      <th id=\"T_c3aaf_level0_col5\" class=\"col_heading level0 col5\" >std</th>\n",
       "      <th id=\"T_c3aaf_level0_col6\" class=\"col_heading level0 col6\" >min</th>\n",
       "      <th id=\"T_c3aaf_level0_col7\" class=\"col_heading level0 col7\" >max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >column name</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c3aaf_level0_row0\" class=\"row_heading level0 row0\" >USER_ID</th>\n",
       "      <td id=\"T_c3aaf_row0_col0\" class=\"data row0 col0\" >int64</td>\n",
       "      <td id=\"T_c3aaf_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_c3aaf_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
       "      <td id=\"T_c3aaf_row0_col3\" class=\"data row0 col3\" >6324</td>\n",
       "      <td id=\"T_c3aaf_row0_col4\" class=\"data row0 col4\" >4981.080000</td>\n",
       "      <td id=\"T_c3aaf_row0_col5\" class=\"data row0 col5\" >2890.590000</td>\n",
       "      <td id=\"T_c3aaf_row0_col6\" class=\"data row0 col6\" >2.000000</td>\n",
       "      <td id=\"T_c3aaf_row0_col7\" class=\"data row0 col7\" >10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3aaf_level0_row1\" class=\"row_heading level0 row1\" >VARIANT_NAME</th>\n",
       "      <td id=\"T_c3aaf_row1_col0\" class=\"data row1 col0\" >object</td>\n",
       "      <td id=\"T_c3aaf_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "      <td id=\"T_c3aaf_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
       "      <td id=\"T_c3aaf_row1_col3\" class=\"data row1 col3\" >2</td>\n",
       "      <td id=\"T_c3aaf_row1_col4\" class=\"data row1 col4\" >N/A</td>\n",
       "      <td id=\"T_c3aaf_row1_col5\" class=\"data row1 col5\" >N/A</td>\n",
       "      <td id=\"T_c3aaf_row1_col6\" class=\"data row1 col6\" >N/A</td>\n",
       "      <td id=\"T_c3aaf_row1_col7\" class=\"data row1 col7\" >N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3aaf_level0_row2\" class=\"row_heading level0 row2\" >REVENUE</th>\n",
       "      <td id=\"T_c3aaf_row2_col0\" class=\"data row2 col0\" >float64</td>\n",
       "      <td id=\"T_c3aaf_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "      <td id=\"T_c3aaf_row2_col2\" class=\"data row2 col2\" >0.000000</td>\n",
       "      <td id=\"T_c3aaf_row2_col3\" class=\"data row2 col3\" >101</td>\n",
       "      <td id=\"T_c3aaf_row2_col4\" class=\"data row2 col4\" >0.100000</td>\n",
       "      <td id=\"T_c3aaf_row2_col5\" class=\"data row2 col5\" >2.320000</td>\n",
       "      <td id=\"T_c3aaf_row2_col6\" class=\"data row2 col6\" >0.000000</td>\n",
       "      <td id=\"T_c3aaf_row2_col7\" class=\"data row2 col7\" >196.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3aaf_level0_row3\" class=\"row_heading level0 row3\" >number of duplicate rows</th>\n",
       "      <td id=\"T_c3aaf_row3_col0\" class=\"data row3 col0\" >2067</td>\n",
       "      <td id=\"T_c3aaf_row3_col1\" class=\"data row3 col1\" >2067</td>\n",
       "      <td id=\"T_c3aaf_row3_col2\" class=\"data row3 col2\" >2067.000000</td>\n",
       "      <td id=\"T_c3aaf_row3_col3\" class=\"data row3 col3\" >2067</td>\n",
       "      <td id=\"T_c3aaf_row3_col4\" class=\"data row3 col4\" >2067</td>\n",
       "      <td id=\"T_c3aaf_row3_col5\" class=\"data row3 col5\" >2067</td>\n",
       "      <td id=\"T_c3aaf_row3_col6\" class=\"data row3 col6\" >2067</td>\n",
       "      <td id=\"T_c3aaf_row3_col7\" class=\"data row3 col7\" >2067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x12c969400>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summary(df):\n",
    "    print(f'data shape: {df.shape}')\n",
    "\n",
    "    # Get data types\n",
    "    dtypes_df = pd.DataFrame(df.dtypes, columns=['data type'])\n",
    "\n",
    "    # Count missing values\n",
    "    missing_df = pd.DataFrame(df.isnull().sum(), columns=['number of missing values'])\n",
    "    missing_df['percent missing'] = (df.isnull().mean() * 100).round(2)\n",
    "    \n",
    "    # Count unique values\n",
    "    unique_df = pd.DataFrame(df.nunique(), columns=['number of unique values'])\n",
    "\n",
    "    # Describe statistics\n",
    "    desc_df = df.describe().T\n",
    "    stats_df = desc_df[['mean', 'std', 'min', 'max']].copy()\n",
    "    stats_df['mean'] = stats_df['mean'].round(2)\n",
    "    stats_df['std'] = stats_df['std'].round(2)\n",
    "    stats_df['min'] = stats_df['min'].round(2)\n",
    "    stats_df['max'] = stats_df['max'].round(2)\n",
    "\n",
    "    # Count duplicate rows\n",
    "    duplicate_rows = df.duplicated().sum()\n",
    " \n",
    "    # Concatenate all dataframes\n",
    "    summary_df = pd.concat([dtypes_df, missing_df, unique_df, stats_df], axis=1)\n",
    "    summary_df.loc['number of duplicate rows'] = duplicate_rows\n",
    "    summary_df = summary_df.fillna('N/A')\n",
    "    summary_df = summary_df.reset_index().rename(columns={'index': 'column name'})\n",
    "    summary_df = summary_df.set_index('column name')\n",
    "    summary_df.loc['number of duplicate rows'] = duplicate_rows\n",
    "\n",
    "    styled_summary = summary_df.style.background_gradient(cmap='GnBu')\n",
    "    return styled_summary\n",
    "   \n",
    "\n",
    "summary(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4984, 3)\n",
      "(5016, 3)\n"
     ]
    }
   ],
   "source": [
    "# Variable definition \n",
    "\n",
    "control = df.loc[df['VARIANT_NAME'] == 'control']\n",
    "variant = df.loc[df['VARIANT_NAME'] == 'variant']\n",
    "\n",
    "print(control.shape)\n",
    "print(variant.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypotheses \n",
    "\n",
    "H0: There is no significant different in revenue brought by users between the control group (existing membership model) and the variant group (new membership model) in the A/B test.\n",
    "\n",
    "H1: There is a significant difference in revenue brought by users between the control group (existing memebrship model) and the variant group (new membership model) in the A/B test, indicating that the new membership model leads to either an increase or decrease in revenue compared to the existing model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control group mean revenue: 0.12901284109149277\n",
      "Variant group mean revenue: 0.07006977671451356\n"
     ]
    }
   ],
   "source": [
    "print('Control group mean revenue:', control['REVENUE'].mean())\n",
    "print('Variant group mean revenue:', variant['REVENUE'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normality variance (Shapiro-Wilk test)\n",
    "We can use the Shapiro-Wilk test to check for normality. This test assesses whether a sample comes from a normally distributed population. \n",
    "\n",
    "H0: null hypothesis; the data follows a normal distribution \n",
    "H1: alternative hypothesis; assymes that the data does not follow a normal distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro-Wilk test for control group - p-value: 2.4983285100057203e-95\n",
      "Shapiro-Wilk test for variant group - p-value: 2.7310104028899288e-95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/issrar/venvs/datasci/lib/python3.13/site-packages/scipy/stats/_axis_nan_policy.py:586: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 5016.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Perform the Shapiro-Wilk test for normality\n",
    "\n",
    "shapiro_control = shapiro(control['REVENUE'])\n",
    "shapiro_variant = shapiro(variant['REVENUE'])\n",
    "print('Shapiro-Wilk test for control group - p-value:', shapiro_control.pvalue) \n",
    "print('Shapiro-Wilk test for variant group - p-value:', shapiro_variant.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-valeu from the Shapiro-Wilk test may not be accurate when dealing with sample sizes larger than 5000 and our sample sizes are around that size, these p-value results may not be realiable and we must consider alternatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Anderson-Darling test\n",
    "For alrge sample sizes, the Anderson-Darling test is an alternative that can access normality. it provides both critical values and a statistic, which we compare. A higher statistic value suggests stronger evidence against the null hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anderson-Darling test for control group - statistic: 1855.221244001521\n",
      "Anderson-Darling test for control group - critical values: [0.576 0.655 0.786 0.917 1.091]\n",
      "Anderson-Darling test for variant group - statistic: 1865.809035320146\n",
      "Anderson-Darling test for variant group - critical values: [0.576 0.655 0.786 0.917 1.091]\n"
     ]
    }
   ],
   "source": [
    "# Perform the Anderson-Darling test for normality\n",
    "anderson_control = anderson(control['REVENUE'])\n",
    "anderson_variant = anderson(variant['REVENUE'])\n",
    "\n",
    "# Extract critical values and statistic from the test results \n",
    "anderson_control_stat = anderson_control.statistic\n",
    "anderson_variant_stat = anderson_variant.statistic\n",
    "anderson_control_critical = anderson_control.critical_values\n",
    "anderson_variant_critical = anderson_variant.critical_values\n",
    "\n",
    "# Print the critical values and statistic\n",
    "print('Anderson-Darling test for control group - statistic:', anderson_control_stat)\n",
    "print('Anderson-Darling test for control group - critical values:', anderson_control_critical)\n",
    "print('Anderson-Darling test for variant group - statistic:', anderson_variant_stat)\n",
    "print('Anderson-Darling test for variant group - critical values:', anderson_variant_critical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data deviates significantly from the expected bell curve pattern. \n",
    "\n",
    "Need approach A/B test with caution. Since normality assympotions not met, t-tests and ANOVA may not be appropriate for comparing means between groups. \n",
    "\n",
    "We should consider non-parametric tests/transformations to handle the non-normality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kolmogorov-Smirnov test\n",
    "\n",
    "Another test for asssessing the goodness-of-fit between the empirical distribution function of the data and normal distribution. \n",
    "\n",
    "KS statistic (D-value): a larger KS statistic indicates a greater deviation from normality. \n",
    "P-value: low p-value suggests strong evidence to reject null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolmogorov-Smirnov test for control group - statistic: 0.5\n",
      "Kolmogorov-Smirnov test for control group - p-value: 0.0\n",
      "Kolmogorov-Smirnov test for variant group - statistic: 0.5\n",
      "Kolmogorov-Smirnov test for variant group - p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Perform Kolmogorov-Smirnov test for normality\n",
    "ks_control = kstest(control['REVENUE'], 'norm')\n",
    "ks_variant = kstest(variant['REVENUE'], 'norm')\n",
    "print('Kolmogorov-Smirnov test for control group - statistic:', ks_control.statistic)\n",
    "print('Kolmogorov-Smirnov test for control group - p-value:', ks_control.pvalue)\n",
    "print('Kolmogorov-Smirnov test for variant group - statistic:', ks_variant.statistic)\n",
    "print('Kolmogorov-Smirnov test for variant group - p-value:', ks_variant.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinforces previous normality test results: neither control nor variant groups follow a normal distribution. \n",
    "Non-parametric tests should be consdiered to endure accurate conclusions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mann-Whitney U test\n",
    "wikipedia: \"since the Mann–Whitney U test is an ordinal test, medians are usually recommended\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann-Whitney U test - statistic: 12521564.0\n",
      "Mann-Whitney U test - p-value: 0.47825247965294926\n"
     ]
    }
   ],
   "source": [
    "# Perform Mann-Whitney U test\n",
    "mannwhitney = mannwhitneyu(control['REVENUE'], variant['REVENUE'])\n",
    "print('Mann-Whitney U test - statistic:', mannwhitney.statistic)\n",
    "print('Mann-Whitney U test - p-value:', mannwhitney.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value < 0.5  so we don't find a statistically significant difference between the *medians* of the control and variant groups in terms of income brought by users.\n",
    "\n",
    "\n",
    "=> the modifications made in the variant group did not lead to a significant change in user income compared to the control group during the A/B test. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
